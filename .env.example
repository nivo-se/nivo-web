# ============================================================================
# Nivo Environment Variables
# ============================================================================
# Copy this file to .env and fill in your actual values
# cp .env.example .env

# ----------------------------------------------------------------------------
# App Environment
# ----------------------------------------------------------------------------
# local = dev with optional auth; prod = require JWT for /api routes
APP_ENV=local
# When true (typically in prod), backend requires Authorization: Bearer <token>
REQUIRE_AUTH=false

# ----------------------------------------------------------------------------
# Database Configuration
# ----------------------------------------------------------------------------
# Options: local (SQLite), supabase, postgres (local Docker Postgres)
# Prod: use supabase for hosted Postgres + Auth
DATABASE_SOURCE=local
LOCAL_DB_PATH=data/nivo_optimized.db

# Local Postgres (when DATABASE_SOURCE=postgres)
# Requires: docker compose up -d (maps host 5433 -> container 5432)
POSTGRES_HOST=localhost
POSTGRES_PORT=5433
POSTGRES_DB=nivo
POSTGRES_USER=nivo
POSTGRES_PASSWORD=nivo

# ----------------------------------------------------------------------------
# Supabase Configuration (prod: Auth + hosted Postgres)
# ----------------------------------------------------------------------------
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key-here
# JWT secret from Project Settings > API > JWT Secret (for verifying user tokens)
SUPABASE_JWT_SECRET=your-jwt-secret-here
# Alternative: Use anon key if service role key is not available
# SUPABASE_ANON_KEY=your-anon-key-here

# ----------------------------------------------------------------------------
# OpenAI / LLM Configuration
# ----------------------------------------------------------------------------
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini

# LLM Provider (for LMStudio transplant): set LLM_BASE_URL to use local model
# LLM_BASE_URL=http://localhost:1234/v1
# LLM_API_KEY=lm-studio
# LLM_MODEL=your-model-name
# LLM_PROVIDER=openai_compat

# ----------------------------------------------------------------------------
# Redis Configuration (for background job queues)
# ----------------------------------------------------------------------------
REDIS_URL=redis://localhost:6379/0

# ----------------------------------------------------------------------------
# Web Scraping & Enrichment
# ----------------------------------------------------------------------------
# SerpAPI for website lookup (optional but recommended)
SERPAPI_KEY=your-serpapi-key-here

# Puppeteer Service (optional - for deep scraping of dynamic sites)
# Option 1: Use Browserless.io (recommended for production)
# PUPPETEER_SERVICE_URL=https://chrome.browserless.io/scrape
# PUPPETEER_SERVICE_TOKEN=your-browserless-token

# Option 2: Use your own Railway-deployed Puppeteer worker
# PUPPETEER_SERVICE_URL=https://your-puppeteer-worker.railway.app/scrape
# PUPPETEER_SERVICE_TOKEN=your-api-token-if-needed

# ----------------------------------------------------------------------------
# CRM Export
# ----------------------------------------------------------------------------
COPPER_API_TOKEN=your-copper-api-token-here

# ----------------------------------------------------------------------------
# CORS Configuration
# ----------------------------------------------------------------------------
CORS_ORIGINS=http://localhost:8080,http://localhost:5173

# ----------------------------------------------------------------------------
# Frontend (Vite) - set in Vercel/hosting env, NOT in backend .env
# ----------------------------------------------------------------------------
# VITE_SUPABASE_URL=https://your-project.supabase.co
# VITE_SUPABASE_ANON_KEY=your-anon-key-here
# VITE_API_BASE_URL=https://your-backend.railway.app
